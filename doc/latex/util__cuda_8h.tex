\hypertarget{util__cuda_8h}{}\doxysection{c\+Torch/operators/cuda/util\+\_\+cuda.h File Reference}
\label{util__cuda_8h}\index{cTorch/operators/cuda/util\_cuda.h@{cTorch/operators/cuda/util\_cuda.h}}
\doxysubsection*{Macros}
\begin{DoxyCompactItemize}
\item 
\#define \mbox{\hyperlink{util__cuda_8h_ab30c7973c8663e72149e21b08b1375e5}{C\+T\+H\+\_\+\+C\+U\+D\+A\+\_\+\+T\+H\+R\+E\+A\+D\+S\+\_\+\+P\+E\+R\+\_\+\+B\+L\+O\+CK}}~1024
\begin{DoxyCompactList}\small\item\em thread per block \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\+\_\+cth\+\_\+cuda\+\_\+kernel\+\_\+func\+\_\+float}}(kernel\+\_\+func\+\_\+name)~kernel\+\_\+func\+\_\+name\#\#\+\_\+f
\begin{DoxyCompactList}\small\item\em Kernel function name for float. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\+\_\+cth\+\_\+cuda\+\_\+kernel\+\_\+func\+\_\+double}}(kernel\+\_\+func\+\_\+name)~kernel\+\_\+func\+\_\+name\#\#\+\_\+d
\begin{DoxyCompactList}\small\item\em Kernel function name for double. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a662551b719441dd5ed284bc55a381957}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+unary\+\_\+kernel}}(kernel\+\_\+func\+\_\+name,  f\+\_\+func,  d\+\_\+func)
\begin{DoxyCompactList}\small\item\em Layout two kernel functions based on kernel func for float and double. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a8d8c020bf0f2d82e0deeeb396ede7d36}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+unary\+\_\+kernel\+\_\+type}}(kernel\+\_\+func\+\_\+name,  data\+\_\+type,  func)
\begin{DoxyCompactList}\small\item\em Implement a unary cuda kernel function. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a5f6aeec848dcfc5fbdc76d9a5af2ab9d}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel}}(kernel\+\_\+func\+\_\+name,  f\+\_\+func,  d\+\_\+func)
\begin{DoxyCompactList}\small\item\em Layout two kernel functions based on kernel func for float and double. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_ab1448fa2df9ee0faac52fe87c14c273e}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+type}}( kernel\+\_\+func\+\_\+name,  data\+\_\+type,  func)
\begin{DoxyCompactList}\small\item\em Implement a bina cuda kernel function. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_aaecf4832f5d4b451f47fd6f82058fda2}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+generic}}( kernel\+\_\+func\+\_\+name,  f\+\_\+block,  d\+\_\+block)
\begin{DoxyCompactList}\small\item\em Layout two kernel functions based on kernel func for float and double. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_ab9290297a1617a9509a1794bfabfbc19}{\+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+type\+\_\+generic}}( kernel\+\_\+func\+\_\+name,  data\+\_\+type,  generic\+\_\+block)
\begin{DoxyCompactList}\small\item\em Implement a bina cuda kernel function with generic block. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a97d303296102587b299c1ec844cdc0c7}{\+\_\+cth\+\_\+cuda\+\_\+unary\+\_\+block}}( data\+\_\+type,  in\+\_\+ptr,  out\+\_\+ptr,  N,  kernel,  threads\+\_\+per\+\_\+block,  device)
\begin{DoxyCompactList}\small\item\em Unary operator working block. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a6c866d670d84f165d82617b12aef8fc5}{\+\_\+cth\+\_\+cuda\+\_\+unary\+\_\+workflow}}( data\+\_\+type,  in\+\_\+ptr,  out\+\_\+ptr,  N,  threads\+\_\+per\+\_\+block,  kernel\+\_\+func\+\_\+name,  device)
\begin{DoxyCompactList}\small\item\em consturct a unary op workflow \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_af97113e8753959c55140141c1e892812}{\+\_\+cth\+\_\+cuda\+\_\+binary\+\_\+block}}( data\+\_\+type,  in\+\_\+ptr\+\_\+1,  in\+\_\+ptr\+\_\+2,  out\+\_\+ptr,  N,  kernel,  threads\+\_\+per\+\_\+block,  device)
\begin{DoxyCompactList}\small\item\em Unary operator working block. \end{DoxyCompactList}\item 
\#define \mbox{\hyperlink{util__cuda_8h_a94fb0890c7ef43f9cb3c20c4b17140c6}{\+\_\+cth\+\_\+cuda\+\_\+binary\+\_\+workflow}}( data\+\_\+type,  in\+\_\+ptr\+\_\+1,  in\+\_\+ptr\+\_\+2,  out\+\_\+ptr,  N,  threads\+\_\+per\+\_\+block,  kernel\+\_\+func\+\_\+name,  device)
\begin{DoxyCompactList}\small\item\em consturct a binary op workflow \end{DoxyCompactList}\end{DoxyCompactItemize}


\doxysubsection{Macro Definition Documentation}
\mbox{\Hypertarget{util__cuda_8h_af97113e8753959c55140141c1e892812}\label{util__cuda_8h_af97113e8753959c55140141c1e892812}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_binary\_block@{\_cth\_cuda\_binary\_block}}
\index{\_cth\_cuda\_binary\_block@{\_cth\_cuda\_binary\_block}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_binary\_block}{\_cth\_cuda\_binary\_block}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+binary\+\_\+block(\begin{DoxyParamCaption}\item[{}]{data\+\_\+type,  }\item[{}]{in\+\_\+ptr\+\_\+1,  }\item[{}]{in\+\_\+ptr\+\_\+2,  }\item[{}]{out\+\_\+ptr,  }\item[{}]{N,  }\item[{}]{kernel,  }\item[{}]{threads\+\_\+per\+\_\+block,  }\item[{}]{device }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \textcolor{keywordflow}{do} \{                                                                         \(\backslash\)}
\DoxyCodeLine{    int size = N * \textcolor{keyword}{sizeof}(data\_type);                                          \(\backslash\)}
\DoxyCodeLine{    data\_type *in\_ptr\_1\_d;                                                     \(\backslash\)}
\DoxyCodeLine{    data\_type *in\_ptr\_2\_d;                                                     \(\backslash\)}
\DoxyCodeLine{    data\_type *out\_ptr\_d;                                                      \(\backslash\)}
\DoxyCodeLine{    if (device == \mbox{\hyperlink{consts_8h_a721b3631937c7eb5ba61846c2f93398ea57f98806108a788638ff25f7b5a51b2c}{CTH\_TENSOR\_DEVICE\_NORMAL}}) \{                                  \(\backslash\)}
\DoxyCodeLine{      cudaMalloc(\&in\_ptr\_1\_d, size);                                           \(\backslash\)}
\DoxyCodeLine{      cudaMalloc(\&in\_ptr\_2\_d, size);                                           \(\backslash\)}
\DoxyCodeLine{      cudaMalloc(\&out\_ptr\_d, size);                                            \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(in\_ptr\_1\_d, in\_ptr\_1, size, cudaMemcpyHostToDevice);          \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(in\_ptr\_2\_d, in\_ptr\_2, size, cudaMemcpyHostToDevice);          \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(out\_ptr\_d, out\_ptr, size, cudaMemcpyHostToDevice);            \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \{                                                                   \(\backslash\)}
\DoxyCodeLine{      in\_ptr\_1\_d = (data\_type *)in\_ptr\_1;                                      \(\backslash\)}
\DoxyCodeLine{      in\_ptr\_1\_d = (data\_type *)in\_ptr\_1;                                      \(\backslash\)}
\DoxyCodeLine{      out\_ptr\_d = (data\_type *)out\_ptr;                                        \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{                                                                               \(\backslash\)}
\DoxyCodeLine{    int num\_blocks = (N + threads\_per\_block -\/ 1) / threads\_per\_block;          \(\backslash\)}
\DoxyCodeLine{    kernel<<<num\_blocks, threads\_per\_block>>>(                                 \(\backslash\)}
\DoxyCodeLine{        in\_ptr\_1\_d, in\_ptr\_2\_d, out\_ptr\_d, N);                                 \(\backslash\)}
\DoxyCodeLine{                                                                               \(\backslash\)}
\DoxyCodeLine{    if (device == \mbox{\hyperlink{consts_8h_a721b3631937c7eb5ba61846c2f93398ea57f98806108a788638ff25f7b5a51b2c}{CTH\_TENSOR\_DEVICE\_NORMAL}}) \{                                  \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(out\_ptr, out\_ptr\_d, size, cudaMemcpyDeviceToHost);            \(\backslash\)}
\DoxyCodeLine{      cudaFree(in\_ptr\_1\_d);                                                    \(\backslash\)}
\DoxyCodeLine{      cudaFree(in\_ptr\_2\_d);                                                    \(\backslash\)}
\DoxyCodeLine{      cudaFree(out\_ptr\_d);                                                     \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \} \textcolor{keywordflow}{while} (0)}

\end{DoxyCode}


Unary operator working block. 

\mbox{\Hypertarget{util__cuda_8h_a94fb0890c7ef43f9cb3c20c4b17140c6}\label{util__cuda_8h_a94fb0890c7ef43f9cb3c20c4b17140c6}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_binary\_workflow@{\_cth\_cuda\_binary\_workflow}}
\index{\_cth\_cuda\_binary\_workflow@{\_cth\_cuda\_binary\_workflow}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_binary\_workflow}{\_cth\_cuda\_binary\_workflow}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+binary\+\_\+workflow(\begin{DoxyParamCaption}\item[{}]{data\+\_\+type,  }\item[{}]{in\+\_\+ptr\+\_\+1,  }\item[{}]{in\+\_\+ptr\+\_\+2,  }\item[{}]{out\+\_\+ptr,  }\item[{}]{N,  }\item[{}]{threads\+\_\+per\+\_\+block,  }\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{device }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \textcolor{keywordflow}{do} \{                                                                         \(\backslash\)}
\DoxyCodeLine{    if (data\_type == \mbox{\hyperlink{consts_8h_a4b8846c2fb1629129ab48cd874d22355a3c2141e561fafc5c113a1e0f74ee8494}{CTH\_TENSOR\_DATA\_TYPE\_FLOAT\_32}}) \{                          \(\backslash\)}
\DoxyCodeLine{      \_cth\_cuda\_binary\_block(                                                  \(\backslash\)}
\DoxyCodeLine{          \textcolor{keywordtype}{float},                                                               \(\backslash\)}
\DoxyCodeLine{          in\_ptr\_1,                                                            \(\backslash\)}
\DoxyCodeLine{          in\_ptr\_2,                                                            \(\backslash\)}
\DoxyCodeLine{          out\_ptr,                                                             \(\backslash\)}
\DoxyCodeLine{          N,                                                                   \(\backslash\)}
\DoxyCodeLine{          \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\_cth\_cuda\_kernel\_func\_float}}(kernel\_func\_name),                       \(\backslash\)}
\DoxyCodeLine{          threads\_per\_block,                                                   \(\backslash\)}
\DoxyCodeLine{          device);                                                             \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (data\_type == \mbox{\hyperlink{consts_8h_a4b8846c2fb1629129ab48cd874d22355a3b3e271ef78a842c489769d06a245984}{CTH\_TENSOR\_DATA\_TYPE\_FLOAT\_64}}) \{                   \(\backslash\)}
\DoxyCodeLine{      \_cth\_cuda\_binary\_block(                                                  \(\backslash\)}
\DoxyCodeLine{          \textcolor{keywordtype}{double},                                                              \(\backslash\)}
\DoxyCodeLine{          in\_ptr\_1,                                                            \(\backslash\)}
\DoxyCodeLine{          in\_ptr\_2,                                                            \(\backslash\)}
\DoxyCodeLine{          out\_ptr,                                                             \(\backslash\)}
\DoxyCodeLine{          N,                                                                   \(\backslash\)}
\DoxyCodeLine{          \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\_cth\_cuda\_kernel\_func\_double}}(kernel\_func\_name),                      \(\backslash\)}
\DoxyCodeLine{          threads\_per\_block,                                                   \(\backslash\)}
\DoxyCodeLine{          device);                                                             \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \{                                                                   \(\backslash\)}
\DoxyCodeLine{      FAIL\_EXIT(\mbox{\hyperlink{logger__util_8h_ad9ab19b2b3e07e3ac860411d60ae4e52}{CTH\_LOG\_ERR}}, \textcolor{stringliteral}{"Unsupported data type on CUDA backend."});        \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \} \textcolor{keywordflow}{while} (0)}

\end{DoxyCode}


consturct a binary op workflow 

\mbox{\Hypertarget{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}\label{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_kernel\_func\_double@{\_cth\_cuda\_kernel\_func\_double}}
\index{\_cth\_cuda\_kernel\_func\_double@{\_cth\_cuda\_kernel\_func\_double}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_kernel\_func\_double}{\_cth\_cuda\_kernel\_func\_double}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+kernel\+\_\+func\+\_\+double(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name }\end{DoxyParamCaption})~kernel\+\_\+func\+\_\+name\#\#\+\_\+d}



Kernel function name for double. 

\mbox{\Hypertarget{util__cuda_8h_a188a9e02b690006620b6255288053726}\label{util__cuda_8h_a188a9e02b690006620b6255288053726}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_kernel\_func\_float@{\_cth\_cuda\_kernel\_func\_float}}
\index{\_cth\_cuda\_kernel\_func\_float@{\_cth\_cuda\_kernel\_func\_float}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_kernel\_func\_float}{\_cth\_cuda\_kernel\_func\_float}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+kernel\+\_\+func\+\_\+float(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name }\end{DoxyParamCaption})~kernel\+\_\+func\+\_\+name\#\#\+\_\+f}



Kernel function name for float. 

\mbox{\Hypertarget{util__cuda_8h_a97d303296102587b299c1ec844cdc0c7}\label{util__cuda_8h_a97d303296102587b299c1ec844cdc0c7}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_unary\_block@{\_cth\_cuda\_unary\_block}}
\index{\_cth\_cuda\_unary\_block@{\_cth\_cuda\_unary\_block}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_unary\_block}{\_cth\_cuda\_unary\_block}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+unary\+\_\+block(\begin{DoxyParamCaption}\item[{}]{data\+\_\+type,  }\item[{}]{in\+\_\+ptr,  }\item[{}]{out\+\_\+ptr,  }\item[{}]{N,  }\item[{}]{kernel,  }\item[{}]{threads\+\_\+per\+\_\+block,  }\item[{}]{device }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \textcolor{keywordflow}{do} \{                                                                         \(\backslash\)}
\DoxyCodeLine{    int size = N * \textcolor{keyword}{sizeof}(data\_type);                                          \(\backslash\)}
\DoxyCodeLine{    data\_type *in\_ptr\_d;                                                       \(\backslash\)}
\DoxyCodeLine{    data\_type *out\_ptr\_d;                                                      \(\backslash\)}
\DoxyCodeLine{    if (device == \mbox{\hyperlink{consts_8h_a721b3631937c7eb5ba61846c2f93398ea57f98806108a788638ff25f7b5a51b2c}{CTH\_TENSOR\_DEVICE\_NORMAL}}) \{                                  \(\backslash\)}
\DoxyCodeLine{      cudaMalloc(\&in\_ptr\_d, size);                                             \(\backslash\)}
\DoxyCodeLine{      cudaMalloc(\&out\_ptr\_d, size);                                            \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(in\_ptr\_d, in\_ptr, size, cudaMemcpyHostToDevice);              \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(out\_ptr\_d, out\_ptr, size, cudaMemcpyHostToDevice);            \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \{                                                                   \(\backslash\)}
\DoxyCodeLine{      in\_ptr\_d = (data\_type *)in\_ptr;                                          \(\backslash\)}
\DoxyCodeLine{      out\_ptr\_d = (data\_type *)out\_ptr;                                        \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{                                                                               \(\backslash\)}
\DoxyCodeLine{    int num\_blocks = (N + threads\_per\_block -\/ 1) / threads\_per\_block;          \(\backslash\)}
\DoxyCodeLine{    kernel<<<num\_blocks, threads\_per\_block>>>(in\_ptr\_d, out\_ptr\_d, N);         \(\backslash\)}
\DoxyCodeLine{                                                                               \(\backslash\)}
\DoxyCodeLine{    if (device == \mbox{\hyperlink{consts_8h_a721b3631937c7eb5ba61846c2f93398ea57f98806108a788638ff25f7b5a51b2c}{CTH\_TENSOR\_DEVICE\_NORMAL}}) \{                                  \(\backslash\)}
\DoxyCodeLine{      cudaMemcpy(out\_ptr, out\_ptr\_d, size, cudaMemcpyDeviceToHost);            \(\backslash\)}
\DoxyCodeLine{      cudaFree(in\_ptr\_d);                                                      \(\backslash\)}
\DoxyCodeLine{      cudaFree(out\_ptr\_d);                                                     \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \} \textcolor{keywordflow}{while} (0)}

\end{DoxyCode}


Unary operator working block. 

\mbox{\Hypertarget{util__cuda_8h_a6c866d670d84f165d82617b12aef8fc5}\label{util__cuda_8h_a6c866d670d84f165d82617b12aef8fc5}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_cuda\_unary\_workflow@{\_cth\_cuda\_unary\_workflow}}
\index{\_cth\_cuda\_unary\_workflow@{\_cth\_cuda\_unary\_workflow}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_cuda\_unary\_workflow}{\_cth\_cuda\_unary\_workflow}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+cuda\+\_\+unary\+\_\+workflow(\begin{DoxyParamCaption}\item[{}]{data\+\_\+type,  }\item[{}]{in\+\_\+ptr,  }\item[{}]{out\+\_\+ptr,  }\item[{}]{N,  }\item[{}]{threads\+\_\+per\+\_\+block,  }\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{device }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \textcolor{keywordflow}{do} \{                                                                         \(\backslash\)}
\DoxyCodeLine{    if (data\_type == \mbox{\hyperlink{consts_8h_a4b8846c2fb1629129ab48cd874d22355a3c2141e561fafc5c113a1e0f74ee8494}{CTH\_TENSOR\_DATA\_TYPE\_FLOAT\_32}}) \{                          \(\backslash\)}
\DoxyCodeLine{      \_cth\_cuda\_unary\_block(                                                   \(\backslash\)}
\DoxyCodeLine{          \textcolor{keywordtype}{float},                                                               \(\backslash\)}
\DoxyCodeLine{          in\_ptr,                                                              \(\backslash\)}
\DoxyCodeLine{          out\_ptr,                                                             \(\backslash\)}
\DoxyCodeLine{          N,                                                                   \(\backslash\)}
\DoxyCodeLine{          \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\_cth\_cuda\_kernel\_func\_float}}(kernel\_func\_name),                       \(\backslash\)}
\DoxyCodeLine{          threads\_per\_block,                                                   \(\backslash\)}
\DoxyCodeLine{          device);                                                             \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \textcolor{keywordflow}{if} (data\_type == \mbox{\hyperlink{consts_8h_a4b8846c2fb1629129ab48cd874d22355a3b3e271ef78a842c489769d06a245984}{CTH\_TENSOR\_DATA\_TYPE\_FLOAT\_64}}) \{                   \(\backslash\)}
\DoxyCodeLine{      \_cth\_cuda\_unary\_block(                                                   \(\backslash\)}
\DoxyCodeLine{          \textcolor{keywordtype}{double},                                                              \(\backslash\)}
\DoxyCodeLine{          in\_ptr,                                                              \(\backslash\)}
\DoxyCodeLine{          out\_ptr,                                                             \(\backslash\)}
\DoxyCodeLine{          N,                                                                   \(\backslash\)}
\DoxyCodeLine{          \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\_cth\_cuda\_kernel\_func\_double}}(kernel\_func\_name),                      \(\backslash\)}
\DoxyCodeLine{          threads\_per\_block,                                                   \(\backslash\)}
\DoxyCodeLine{          device);                                                             \(\backslash\)}
\DoxyCodeLine{    \} \textcolor{keywordflow}{else} \{                                                                   \(\backslash\)}
\DoxyCodeLine{      FAIL\_EXIT(\mbox{\hyperlink{logger__util_8h_ad9ab19b2b3e07e3ac860411d60ae4e52}{CTH\_LOG\_ERR}}, \textcolor{stringliteral}{"Unsupported data type on CUDA backend."});        \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \} \textcolor{keywordflow}{while} (0)}

\end{DoxyCode}


consturct a unary op workflow 

\mbox{\Hypertarget{util__cuda_8h_a5f6aeec848dcfc5fbdc76d9a5af2ab9d}\label{util__cuda_8h_a5f6aeec848dcfc5fbdc76d9a5af2ab9d}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_binary\_kernel@{\_cth\_declare\_cuda\_binary\_kernel}}
\index{\_cth\_declare\_cuda\_binary\_kernel@{\_cth\_declare\_cuda\_binary\_kernel}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_binary\_kernel}{\_cth\_declare\_cuda\_binary\_kernel}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{f\+\_\+func,  }\item[{}]{d\+\_\+func }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \mbox{\hyperlink{util__cuda_8h_ab1448fa2df9ee0faac52fe87c14c273e}{\_cth\_declare\_cuda\_binary\_kernel\_type}}(                                        \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\_cth\_cuda\_kernel\_func\_float}}(kernel\_func\_name), \textcolor{keywordtype}{float}, f\_func);           \(\backslash\)}
\DoxyCodeLine{  \_cth\_declare\_cuda\_binary\_kernel\_type(                                        \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\_cth\_cuda\_kernel\_func\_double}}(kernel\_func\_name), \textcolor{keywordtype}{double}, d\_func)}

\end{DoxyCode}


Layout two kernel functions based on kernel func for float and double. 

This will layout two kernel functions\+:
\begin{DoxyItemize}
\item {\bfseries{global}} void xxx\#\#f(float$\ast$ in\+\_\+ptr\+\_\+1\+\_\+d, float$\ast$ in\+\_\+ptr\+\_\+2\+\_\+d, float$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\}
\item {\bfseries{global}} void xxx\#\#d(double$\ast$ in\+\_\+ptr\+\_\+1\+\_\+d, double$\ast$ in\+\_\+ptr\+\_\+2\+\_\+d, double$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\} 
\end{DoxyItemize}\mbox{\Hypertarget{util__cuda_8h_aaecf4832f5d4b451f47fd6f82058fda2}\label{util__cuda_8h_aaecf4832f5d4b451f47fd6f82058fda2}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_binary\_kernel\_generic@{\_cth\_declare\_cuda\_binary\_kernel\_generic}}
\index{\_cth\_declare\_cuda\_binary\_kernel\_generic@{\_cth\_declare\_cuda\_binary\_kernel\_generic}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_binary\_kernel\_generic}{\_cth\_declare\_cuda\_binary\_kernel\_generic}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+generic(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{f\+\_\+block,  }\item[{}]{d\+\_\+block }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \mbox{\hyperlink{util__cuda_8h_ab9290297a1617a9509a1794bfabfbc19}{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic}}(                                \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\_cth\_cuda\_kernel\_func\_float}}(kernel\_func\_name), \textcolor{keywordtype}{float}, f\_block);          \(\backslash\)}
\DoxyCodeLine{  \_cth\_declare\_cuda\_binary\_kernel\_type\_generic(                                \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\_cth\_cuda\_kernel\_func\_double}}(kernel\_func\_name), \textcolor{keywordtype}{double}, d\_block)}

\end{DoxyCode}


Layout two kernel functions based on kernel func for float and double. 

This will layout two kernel functions\+:
\begin{DoxyItemize}
\item {\bfseries{global}} void xxx\#\#f(float$\ast$ in\+\_\+ptr\+\_\+1\+\_\+d, float$\ast$ in\+\_\+ptr\+\_\+2\+\_\+d, float$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\}
\item {\bfseries{global}} void xxx\#\#d(double$\ast$ in\+\_\+ptr\+\_\+1\+\_\+d, double$\ast$ in\+\_\+ptr\+\_\+2\+\_\+d, double$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\} 
\end{DoxyItemize}\mbox{\Hypertarget{util__cuda_8h_ab1448fa2df9ee0faac52fe87c14c273e}\label{util__cuda_8h_ab1448fa2df9ee0faac52fe87c14c273e}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_binary\_kernel\_type@{\_cth\_declare\_cuda\_binary\_kernel\_type}}
\index{\_cth\_declare\_cuda\_binary\_kernel\_type@{\_cth\_declare\_cuda\_binary\_kernel\_type}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_binary\_kernel\_type}{\_cth\_declare\_cuda\_binary\_kernel\_type}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+type(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{data\+\_\+type,  }\item[{}]{func }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \_\_global\_\_ \textcolor{keywordtype}{void} kernel\_func\_name(                                            \(\backslash\)}
\DoxyCodeLine{      data\_type *in\_ptr\_1\_d,                                                   \(\backslash\)}
\DoxyCodeLine{      data\_type *in\_ptr\_2\_d,                                                   \(\backslash\)}
\DoxyCodeLine{      data\_type *out\_ptr\_d,                                                    \(\backslash\)}
\DoxyCodeLine{      \textcolor{keywordtype}{int} N) \{                                                                 \(\backslash\)}
\DoxyCodeLine{    int i = blockDim.x * blockIdx.x + threadIdx.x;                             \(\backslash\)}
\DoxyCodeLine{    if (i < N) \{                                                               \(\backslash\)}
\DoxyCodeLine{      out\_ptr\_d[i] = func(in\_ptr\_1\_d[i], in\_ptr\_2\_d[i]);                       \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \}}

\end{DoxyCode}


Implement a bina cuda kernel function. 

\mbox{\Hypertarget{util__cuda_8h_ab9290297a1617a9509a1794bfabfbc19}\label{util__cuda_8h_ab9290297a1617a9509a1794bfabfbc19}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_binary\_kernel\_type\_generic@{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic}}
\index{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic@{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic}{\_cth\_declare\_cuda\_binary\_kernel\_type\_generic}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+binary\+\_\+kernel\+\_\+type\+\_\+generic(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{data\+\_\+type,  }\item[{}]{generic\+\_\+block }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \_\_global\_\_ \textcolor{keywordtype}{void} kernel\_func\_name(                                            \(\backslash\)}
\DoxyCodeLine{      data\_type *in\_ptr\_1\_d,                                                   \(\backslash\)}
\DoxyCodeLine{      data\_type *in\_ptr\_2\_d,                                                   \(\backslash\)}
\DoxyCodeLine{      data\_type *out\_ptr\_d,                                                    \(\backslash\)}
\DoxyCodeLine{      \textcolor{keywordtype}{int} N) \{                                                                 \(\backslash\)}
\DoxyCodeLine{    int i = blockDim.x * blockIdx.x + threadIdx.x;                             \(\backslash\)}
\DoxyCodeLine{    if (i < N) \{                                                               \(\backslash\)}
\DoxyCodeLine{      generic\_block(in\_ptr\_1\_d, in\_ptr\_2\_d, out\_ptr\_d, i);                     \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \}}

\end{DoxyCode}


Implement a bina cuda kernel function with generic block. 

\mbox{\Hypertarget{util__cuda_8h_a662551b719441dd5ed284bc55a381957}\label{util__cuda_8h_a662551b719441dd5ed284bc55a381957}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_unary\_kernel@{\_cth\_declare\_cuda\_unary\_kernel}}
\index{\_cth\_declare\_cuda\_unary\_kernel@{\_cth\_declare\_cuda\_unary\_kernel}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_unary\_kernel}{\_cth\_declare\_cuda\_unary\_kernel}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+unary\+\_\+kernel(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{f\+\_\+func,  }\item[{}]{d\+\_\+func }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \mbox{\hyperlink{util__cuda_8h_a8d8c020bf0f2d82e0deeeb396ede7d36}{\_cth\_declare\_cuda\_unary\_kernel\_type}}(                                         \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a188a9e02b690006620b6255288053726}{\_cth\_cuda\_kernel\_func\_float}}(kernel\_func\_name), \textcolor{keywordtype}{float}, f\_func);           \(\backslash\)}
\DoxyCodeLine{  \_cth\_declare\_cuda\_unary\_kernel\_type(                                         \(\backslash\)}
\DoxyCodeLine{      \mbox{\hyperlink{util__cuda_8h_a6ead26c028d6a6da9533d7359bc5450f}{\_cth\_cuda\_kernel\_func\_double}}(kernel\_func\_name), \textcolor{keywordtype}{double}, d\_func)}

\end{DoxyCode}


Layout two kernel functions based on kernel func for float and double. 

This will layout two kernel functions\+:
\begin{DoxyItemize}
\item {\bfseries{global}} void xxx\#\#f(float$\ast$ in\+\_\+ptr\+\_\+d, float$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\}
\item {\bfseries{global}} void xxx\#\#d(double$\ast$ in\+\_\+ptr\+\_\+d, double$\ast$ out\+\_\+ptr\+\_\+d, int N)\{...\} 
\end{DoxyItemize}\mbox{\Hypertarget{util__cuda_8h_a8d8c020bf0f2d82e0deeeb396ede7d36}\label{util__cuda_8h_a8d8c020bf0f2d82e0deeeb396ede7d36}} 
\index{util\_cuda.h@{util\_cuda.h}!\_cth\_declare\_cuda\_unary\_kernel\_type@{\_cth\_declare\_cuda\_unary\_kernel\_type}}
\index{\_cth\_declare\_cuda\_unary\_kernel\_type@{\_cth\_declare\_cuda\_unary\_kernel\_type}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{\_cth\_declare\_cuda\_unary\_kernel\_type}{\_cth\_declare\_cuda\_unary\_kernel\_type}}
{\footnotesize\ttfamily \#define \+\_\+cth\+\_\+declare\+\_\+cuda\+\_\+unary\+\_\+kernel\+\_\+type(\begin{DoxyParamCaption}\item[{}]{kernel\+\_\+func\+\_\+name,  }\item[{}]{data\+\_\+type,  }\item[{}]{func }\end{DoxyParamCaption})}

{\bfseries Value\+:}
\begin{DoxyCode}{0}
\DoxyCodeLine{  \_\_global\_\_ \textcolor{keywordtype}{void} kernel\_func\_name(                                            \(\backslash\)}
\DoxyCodeLine{      data\_type *in\_ptr\_d, data\_type *out\_ptr\_d, \textcolor{keywordtype}{int} N) \{                      \(\backslash\)}
\DoxyCodeLine{    int i = blockDim.x * blockIdx.x + threadIdx.x;                             \(\backslash\)}
\DoxyCodeLine{    if (i < N) \{                                                               \(\backslash\)}
\DoxyCodeLine{      out\_ptr\_d[i] = func(in\_ptr\_d[i]);                                        \(\backslash\)}
\DoxyCodeLine{    \}                                                                          \(\backslash\)}
\DoxyCodeLine{  \}}

\end{DoxyCode}


Implement a unary cuda kernel function. 

\mbox{\Hypertarget{util__cuda_8h_ab30c7973c8663e72149e21b08b1375e5}\label{util__cuda_8h_ab30c7973c8663e72149e21b08b1375e5}} 
\index{util\_cuda.h@{util\_cuda.h}!CTH\_CUDA\_THREADS\_PER\_BLOCK@{CTH\_CUDA\_THREADS\_PER\_BLOCK}}
\index{CTH\_CUDA\_THREADS\_PER\_BLOCK@{CTH\_CUDA\_THREADS\_PER\_BLOCK}!util\_cuda.h@{util\_cuda.h}}
\doxysubsubsection{\texorpdfstring{CTH\_CUDA\_THREADS\_PER\_BLOCK}{CTH\_CUDA\_THREADS\_PER\_BLOCK}}
{\footnotesize\ttfamily \#define C\+T\+H\+\_\+\+C\+U\+D\+A\+\_\+\+T\+H\+R\+E\+A\+D\+S\+\_\+\+P\+E\+R\+\_\+\+B\+L\+O\+CK~1024}



thread per block 

