\hypertarget{sharder_8c}{}\doxysection{c\+Torch/sharder.c File Reference}
\label{sharder_8c}\index{cTorch/sharder.c@{cTorch/sharder.c}}
{\ttfamily \#include \char`\"{}c\+Torch/sharder.\+h\char`\"{}}\newline
{\ttfamily \#include $<$tgmath.\+h$>$}\newline
Include dependency graph for sharder.\+c\+:
% FIG 0
\doxysubsection*{Functions}
\begin{DoxyCompactItemize}
\item 
void \mbox{\hyperlink{sharder_8c_a1d0409e74665162ea3fb68e026535605}{cth\+\_\+sharding\+\_\+op\+\_\+elewise}} (\mbox{\hyperlink{structCTHOperator}{C\+T\+H\+Operator}} $\ast$op, \mbox{\hyperlink{consts_8h_aaaedfc356f04494a6b0fab869b439b55}{cth\+\_\+thread\+\_\+n\+\_\+t}} n\+\_\+shards, \mbox{\hyperlink{list__d_8h_aa8ec55b1eb665e3b7e7378dca481845f}{C\+T\+H\+List}}(\mbox{\hyperlink{structCTHOperator}{C\+T\+H\+Operator}}) $\ast$ops)
\item 
void \mbox{\hyperlink{sharder_8c_adaa515559a83630fc72cd47131352e5a}{cth\+\_\+sharding\+\_\+tensor\+\_\+elewise}} (\mbox{\hyperlink{structCTHTensor}{C\+T\+H\+Tensor}} $\ast$tensor, \mbox{\hyperlink{consts_8h_aaaedfc356f04494a6b0fab869b439b55}{cth\+\_\+thread\+\_\+n\+\_\+t}} n\+\_\+shards, \mbox{\hyperlink{list__d_8h_aa8ec55b1eb665e3b7e7378dca481845f}{C\+T\+H\+List}}(\mbox{\hyperlink{structCTHTensor}{C\+T\+H\+Tensor}}) $\ast$tensors)
\end{DoxyCompactItemize}


\doxysubsection{Function Documentation}
\mbox{\Hypertarget{sharder_8c_a1d0409e74665162ea3fb68e026535605}\label{sharder_8c_a1d0409e74665162ea3fb68e026535605}} 
\index{sharder.c@{sharder.c}!cth\_sharding\_op\_elewise@{cth\_sharding\_op\_elewise}}
\index{cth\_sharding\_op\_elewise@{cth\_sharding\_op\_elewise}!sharder.c@{sharder.c}}
\doxysubsubsection{\texorpdfstring{cth\_sharding\_op\_elewise()}{cth\_sharding\_op\_elewise()}}
{\footnotesize\ttfamily void cth\+\_\+sharding\+\_\+op\+\_\+elewise (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{structCTHOperator}{C\+T\+H\+Operator}} $\ast$}]{op,  }\item[{\mbox{\hyperlink{consts_8h_aaaedfc356f04494a6b0fab869b439b55}{cth\+\_\+thread\+\_\+n\+\_\+t}}}]{n\+\_\+shards,  }\item[{\mbox{\hyperlink{list__d_8h_aa8ec55b1eb665e3b7e7378dca481845f}{C\+T\+H\+List}}(\mbox{\hyperlink{structCTHOperator}{C\+T\+H\+Operator}}) $\ast$}]{ops }\end{DoxyParamCaption})}

Sharding an op\textquotesingle{}s inputs \& outputs for element-\/wise operation

New memory allocation\+:
\begin{DoxyItemize}
\item A list of sharded input \& output tensors
\item A list of sharded ops
\end{DoxyItemize}

Params\+:
\begin{DoxyItemize}
\item op\+: the target operator
\item n\+\_\+shards\+: number of sharding pieces
\item ops\+: sharded operator list to be appended
\end{DoxyItemize}

Return\+: List of sharded operator 
\begin{DoxyEnumerate}
\item Create sharded ops and copy all information from the original op
\item Prepare inbound \& outbound tensors for each sharded ops 2.\+1. Shard a tensor 2.\+2. Assign each sharded piece to corresponding sharded op
\end{DoxyEnumerate}\mbox{\Hypertarget{sharder_8c_adaa515559a83630fc72cd47131352e5a}\label{sharder_8c_adaa515559a83630fc72cd47131352e5a}} 
\index{sharder.c@{sharder.c}!cth\_sharding\_tensor\_elewise@{cth\_sharding\_tensor\_elewise}}
\index{cth\_sharding\_tensor\_elewise@{cth\_sharding\_tensor\_elewise}!sharder.c@{sharder.c}}
\doxysubsubsection{\texorpdfstring{cth\_sharding\_tensor\_elewise()}{cth\_sharding\_tensor\_elewise()}}
{\footnotesize\ttfamily void cth\+\_\+sharding\+\_\+tensor\+\_\+elewise (\begin{DoxyParamCaption}\item[{\mbox{\hyperlink{structCTHTensor}{C\+T\+H\+Tensor}} $\ast$}]{tensor,  }\item[{\mbox{\hyperlink{consts_8h_aaaedfc356f04494a6b0fab869b439b55}{cth\+\_\+thread\+\_\+n\+\_\+t}}}]{n\+\_\+shards,  }\item[{\mbox{\hyperlink{list__d_8h_aa8ec55b1eb665e3b7e7378dca481845f}{C\+T\+H\+List}}(\mbox{\hyperlink{structCTHTensor}{C\+T\+H\+Tensor}}) $\ast$}]{tensors }\end{DoxyParamCaption})}

Sharding a tensor for element-\/wise operator

New memory allocation\+:
\begin{DoxyItemize}
\item A list of sharded tensors
\end{DoxyItemize}

Params\+:
\begin{DoxyItemize}
\item tensor\+: target tensor
\item n\+\_\+shards\+: total number of sharding pieces
\item tensors\+: sharded tensor list to be appended
\end{DoxyItemize}

Return\+: List of sharded tensors Shard a tensor into n\+\_\+shards tensors evenly, except the last one which will have all the rest values.

Note\+: When sharding a tensor, we will ignore it\textquotesingle{}s dimension and view the tensor as a flattned 1D tensor.